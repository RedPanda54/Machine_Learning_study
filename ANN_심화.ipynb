{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOuHT7DsUDZYdmG3AkhYSxC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RedPanda54/Machine_Learning_study/blob/main/ANN_%EC%8B%AC%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C93YhmWBvB9s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(10)\n",
        "\n",
        "URL = \"https://raw.githubusercontent.com/RedPanda54/Machine_Learning_study/main/diabetes_prediction_dataset.csv\"\n",
        "df = pd.read_csv(URL)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#중복행 제거\n",
        "df.drop_duplicates(inplace=True)\n",
        "df # 3854개의 행이 제거되었다."
      ],
      "metadata": {
        "id": "5cnBysCvQSAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding for gender column\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df['gender'] = label_encoder.fit_transform(df['gender']) # Female = 0, Male = 1\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PMmF13uhXOYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# smoking history을 숫자형 데이터로 전환\n",
        "smoking_history_mapping = {'never': 0, 'No Info': -1, 'current': 2, 'former': 1, 'ever': 2, 'not current': 0, 'unknown': 999}\n",
        "df['smoking_history'] = df['smoking_history'].map(smoking_history_mapping)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RlpzYOhXyIOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['age'].mod(1) == 0] # 'age' 열의 값이 정수인 행들만 선택\n",
        "df # 필터링 되어 94133개의 행만 남았다."
      ],
      "metadata": {
        "id": "mEPbQNz7gnu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['age'] = df['age'].astype(int) # age열에는 정수만 남았기 때문에 데이터 타입을 int로 변환"
      ],
      "metadata": {
        "id": "Ly5Ux6s-g23y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:-1].values # 마지막 열을 제외한 모든 열을 선택\n",
        "y = df.iloc[:,-1].values  # 마지막 열을 선택, 타켓 변수 = diabetes"
      ],
      "metadata": {
        "id": "Qe2Ky8gaiZrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # train set과 test set을 나누기 위해 import\n",
        "\n",
        "# 데이터를 train set과 test set으로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
        "\n",
        "# train set에서 validation set을 따로 분할\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "r7OG8IRCif9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardization\n",
        "from sklearn import preprocessing\n",
        "stand = preprocessing.StandardScaler()\n",
        "\n",
        "X_train = stand.fit_transform(X_train) # train set의 독립변수\n",
        "X_test = stand.transform(X_test) # test set의 독립변수\n",
        "X_val  = stand.transform(X_val)  # validation의 독립변수"
      ],
      "metadata": {
        "id": "UocOwsJFij8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "8GEcMIhW9SHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "5wma2G629SLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val"
      ],
      "metadata": {
        "id": "inG_r9mZ9SPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "ann = tf.keras.models.Sequential() # Sequential 모델을 생성. 레이어를 순차적으로 쌓아 구성하는 기본적인 신경망 모델\n",
        "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu')) # 첫 번째 은닉층을 추가. 뉴런 수는 6개, 'relu'함수를 activation으로 사용.\n",
        "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu')) # 두 번째 은닉층을 추가. 뉴런 수는 6개, 'relu'함수를 activation으로 사용.\n",
        "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid')) # 출력층을 추가. 뉴런 수는 1개, 'sigmoid'함수를 activation으로 사용."
      ],
      "metadata": {
        "id": "M3Dxa7SjiwJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컴파일 및 훈련\n",
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "ann.fit(X_train, y_train, batch_size=32, epochs = 30, validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "dE7uAJdfjFXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 신경망 정확도\n",
        "ann.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "Yaa9cL4LDdyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**He initialization**"
      ],
      "metadata": {
        "id": "6qiRoNML_bxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization\n",
        "# 뉴런의 개수나 Epoch, 함수 종류도 똑같이 맞췄다.\n",
        "H_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=6, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(units=6, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid', kernel_initializer='he_normal')\n",
        "])\n",
        "\n",
        "# 컴파일 및 훈련\n",
        "H_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "H_model.fit(X_train, y_train, batch_size=32, epochs=30, validation_data = (X_val, y_val))\n"
      ],
      "metadata": {
        "id": "eAceVDTa_nOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# H_model의 정확도\n",
        "H_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "SBh7VONcCrQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Xavier initialization**"
      ],
      "metadata": {
        "id": "MdoRmgJf_jSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Xavier initialization\n",
        "# 마찬가지로 parameter값을 맞췄다.\n",
        "X_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=6, activation='relu', kernel_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(units=6, activation='relu', kernel_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid', kernel_initializer='glorot_uniform')\n",
        "])\n",
        "\n",
        "# 컴파일 및 훈련\n",
        "X_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "X_model.fit(X_train, y_train, batch_size=32, epochs=30, validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "WSD7QOnL_n7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_model의 정확도\n",
        "X_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "EduJIBI_Etxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch normalization**"
      ],
      "metadata": {
        "id": "_v-rmP12Kd4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Batch normalization\n",
        "B_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=6, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(units=6, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 컴파일 및 훈련\n",
        "B_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "B_model.fit(X_train, y_train, batch_size=32, epochs=30)"
      ],
      "metadata": {
        "id": "N4p1PBCiKb1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# B_model의 정확도\n",
        "B_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "2JKkukTCK5oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**L1 regularity**"
      ],
      "metadata": {
        "id": "jbxjJQSkLrn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L1 regularity\n",
        "# L2 regularity를 사용하고 싶으면 regularizers.l2로 바꾸면 된다.\n",
        "L1_model = tf.keras.models.Sequential()\n",
        "L1_model.add(tf.keras.layers.Dense(units = 6, kernel_regularizer=tf.keras.regularizers.l1(0.01), activation = 'relu'))\n",
        "L1_model.add(tf.keras.layers.Dense(units = 6, kernel_regularizer=tf.keras.regularizers.l1(0.01), activation = 'relu'))\n",
        "L1_model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# 컴파일 및 훈련\n",
        "L1_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "history = L1_model.fit(X_train, y_train, batch_size=32, epochs = 30, validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "R98w1fFqLr-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 세트와 검증 세트의 손실 값 저장\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# epoch에 따른 손실 값 그래프\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train Loss')\n",
        "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cEQyh4W7UvPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L1_model의 정확도\n",
        "L1_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "xtv90ttSNzzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drop out**"
      ],
      "metadata": {
        "id": "laWjWb_xTTlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop out\n",
        "# 초기화는 He initialization을 사용.\n",
        "D_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=6, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(units=6, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid', kernel_initializer='he_normal')\n",
        "])\n",
        "\n",
        "# 컴파일 및 훈련\n",
        "D_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "history = D_model.fit(X_train, y_train, batch_size=32, epochs = 30, validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "v1GWuzaETVd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 세트와 검증 세트의 손실 값 저장\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# epoch에 따른 손실 값 그래프\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train Loss')\n",
        "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n",
        "plt.grid(True)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FfbHA5idXDHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# D_model의 정확도\n",
        "D_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "pQCPD1DCUcIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**일부러 성능 저하시키기**"
      ],
      "metadata": {
        "id": "rdiAT2kIZya7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "any_model = tf.keras.models.Sequential()\n",
        "any_model.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))\n",
        "any_model.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))\n",
        "any_model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# 컴파일 및 훈련\n",
        "any_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "any_model.fit(X_train, y_train, batch_size=32, epochs = 1, validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "-I0kq8owZx8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 데이터에 잡음 추가\n",
        "noise_factor = 5\n",
        "noisy_X_train = X_train + noise_factor * np.random.randn(*X_train.shape)\n",
        "noisy_X_val = X_val + noise_factor * np.random.randn(*X_val.shape)\n",
        "\n",
        "any_model = tf.keras.models.Sequential()\n",
        "any_model.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))\n",
        "any_model.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))\n",
        "any_model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "any.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 잡음이 추가된 데이터로 모델 학습\n",
        "history = any.fit(noisy_X_train, y_train, batch_size=32, epochs=10, validation_data=(noisy_X_val, y_val))\n"
      ],
      "metadata": {
        "id": "kZt_PctBbqQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "any.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "e5kQyG0Ec8MJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}